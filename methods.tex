\chapter{Method}
\label{cha:method}

\section{Dataset}
\label{sec:dataset}

Describe the used Dataset, and how it looks like.
The Dataset contains 659 papers in PDF format.

For the bag of words and the neural network a dataset was generated. This dataset contains all chapter names, and the corresponding class. 
At a preprocessing step... stopwords and symbols removed, stemmed, and lower case... Few examples are:

\begin{itemize}[label={}]
  \item introduct: INDRODUCTION
  \item relat work: BACKGROUND
  \item conclus futur work: DISCUSSION
  \item result discuss: RESULTS DISCUSSION
\end{itemize}

Overall the dataset has 2013 enties. The chapter names contain 359 different word tokens.

\section{Preprocessing}
\label{sec:preprocessing}

\subsection{Stop Words}
\label{subsec:stop-words}

\subsection{Stemming}
\label{subsec:stemming}

\section{Data Representation}
\label{sec:data-representation}

Describe the Data Structure from the Tool Output. How it was changed in the preprocessing step. It is stored in the Database. It was used for search queries.  

\section{Chapters to IMRaD mapping}
\label{sec:chapters-to-imrad-mapping}

Descripe general idea

\subsection{Creating the Feature Vector}
\label{subsec:creating-feature-vector}

\begin{tabular}{| c | c | c || c | c | c |}
\hline
\rowcolor{lightblue}
\textbf{word} & \textbf{counted in datase}t & \textbf{feature} & \textbf{word} & \textbf{counted in datase}t & \textbf{feature} \\ \hline
introduct & 457 & yes & data & 16 & yes \\ \hline
conclus & 451 & yes & empir & 14 & yes \\ \hline
work & 324 & yes & vi & 14 & no \\ \hline
relat & 193 & yes & method & 14 & yes \\ \hline
result & 182 & yes & comparison & 14 & yes \\ \hline
experi & 147 & yes & model & 12 & yes \\ \hline
evalu & 143 & yes & vii & 12 & no \\ \hline
futur & 117 & yes & resourc & 11 & yes \\ \hline
abstract & 117 & yes & iii & 10 & no \\ \hline
discuss & 115 & yes & gener & 10 & yes \\ \hline
experiment & 98 & yes & iv & 10 & no \\ \hline
acknowledg & 72 & yes & system & 10 & yes \\ \hline
analysi & 48 & yes & research & 9 & yes \\ \hline
background & 37 & yes & set & 9 & yes \\ \hline
summari & 24 & yes & task & 8 & yes \\ \hline
methodolog & 24 & yes & propos & 8 & yes \\ \hline
setup & 18 & yes & outlook & 7 & yes \\ \hline
dataset & 18 & yes & measur & 7 & yes \\ \hline
previou & 17 & yes & & &\\ \hline
\end{tabular}

\subsection{Classify Chapters via a Neural Network}
\label{subsec:creating-feature-vector}

Describe how the Neural Network is used to label the Capters.

\myfig{accuracy_nn}
      {width=0.80\textwidth}
      {Accuracy during the training of the neural network -- More Description}
      {Accuracy during the training of the neural network}
      {fig:accuracy_nn}

\myfig{loss_nn}
      {width=0.80\textwidth}
      {Loss during the training of the neural network. Categorical Crossentropy is used as loss function}
      {Loss during the training of the neural network}
      {fig:loss_nn}
      
Trainingset with 1610 entries, Testset with 403 entries

loss: 0.060084        \\
acc: 0.989071         \\
recall: 0.971722      \\
precision: 0.998510   \\
f1: 0.984738









%\chapter{Information Retrieval}
%\label{cha:information-retrieval}

\section{Explicit Search}
\label{sec:explicit-search}

Search with Search Queries

\section{More Like This} %TODO: rename
\label{sec:more-like-this}

Search with a single PDF

\section{Recommender Search}
\label{sec:recommender-search}

Search with a Set of PDFs