\chapter{Conclusion}
\label{cha:conclusion}

%In the final chapter we 

\section{Summary}
\label{sec:summary}

We started our work with an motivation section, where we discuss the fast grow of the internet and the resulting importance of search engines. Therefore, search engines help to reduce the time required to find a piece of information, and minimize the number of information sources that need to be searched. In the field of science they help to simplify literature search. 

An advantage of scientific articles is that they have a common structure to increase the readability. This structure is known is IMRaD (Introduction, Method, Results and Discussion). In our work we tackle the question whether it is possible to improve the search result quality while searching for scientific works by using IMRaD structure information. Specifically, 
\begin{enumerate}[label=(\alph*)]
  \item Does the search result improve for explicit search using queries?
  \item Does the search result improve for implicit search using complete scientific papers?
  \item Does the search result improve if only a single chapter of the scientific paper is used for searching?
\end{enumerate}
In the related work section we describe the definition of an information retrieval model. Afterwards, we discuss the $3$ classical models for unstructured text retrieval. First, in the boolean model, documents and queries are represented as sets. Terms are stitched together with boolean operators to formulate user queries. Second, in the vector model, documents and queries are represented asa vector in a t-dimensional space. Third, in the probabilistic model, documents and queries are represented based on probability theory. Specifically by estimating the probability of a term appearing in a relevant document.

Additionally, we describe extensions of the vector-, and the probabilistic model. First, the TF-IDF model is based on the vector space model, and one of the most popular weighting schemes in information retrieval. Second, the BM$25$ model is based on the probabilistic model. It is the result of several experiments by Robertson et. al ~\cite{RobertsonWHGL92, RobertsonWJHG93, RobertsonWJHG94}. Third, the Divergence from Randomness model was introduced by Amati and Rijsbergen ~\cite{AmatiR02} and is a probabilistic model that exhibits characteristics of a language model as well.

Next, we discuss techniques of structured text retrieval models. There we focus specially on $5$ ranking strategies known as contextualization, propagation, aggregation, merging, and zone scores. The model based on zone scores is proposed by Manning et al. ~\cite{manning2008}, and also known as Ranked Boolean Retrieval.

In the last part of the related work we focus on the IMRaD structure in scientific articles. Sollaci and Pereira ~\cite{Sollaci-The-2004} describe in their work that the IMRaD structure began to be adopted in the 1940s, and became the standard format for scientific articles in the 1970s. Furthermore, we discuss IMRaD structure distributions as proposed by Bertin et al. ~\cite{bertin2013}, and how IMRaD structure can be leveraged in information retrieval systems.

In the methods section we started with the description of our generated dataset. There we have $821$ scientific articles in our dataset, and we added additional information like IMRaD mappings, and links between the articles based on citations. Furthermore, we defined our database schema with respect to the article structure and analyze the citation network.

Afterwards, we describe our introduced system and the underlying model. There we design our system to compare various common ranking algorithms. Hence, the ranking algorithms requires to be changeable easily. In addition, our model was designed to work with unstructured as well as structured data. This is reflected by the query language.

In the results and discussion section we describe a measurement for the performance of ranking algorithms. This measurement is required to compare our proposed ranking algorithms.

Finally, we list our study results, and interpret them. This was divided into $3$ parts, which is reflected by our research questions:
\begin{enumerate}[label=(\alph*)]
  \item First, we compare unstructured text retrieval with structured text retrieval according queries. An interpretation of the results captures that it is not necessary to have the overhead of IMRaD chapter features when only a few keywords are used to search for scientific articles. This happens as the keywords define content that should occur anywhere in the articles. Additional constraints that restrict where terms can appear are rather obstructive as they tend to prevent the retrieval of relevant articles.
  \item Second, we discuss implicit search were we use entire scientific articles to search for other articles. When articles are used to search for other articles they can be seen as large and precise queries. IMRaD chapter features are leveraged to define these queries. These are helpful as they introduce constraints that describe the expected content of articles.
  \item Third, we focus on structured text retrieval and the influence of single chapters on the search result. Implicit search with enabled IMRaD chapter features performs a bit better than the highest accuracy of search with single chapters. The highest accuracy was obtained when the Background section is used to search in Introduction sections. One interesting point is that queries for single chapters are one fifth of queries of implicit search, but have almost the same performance.
\end{enumerate}

\section{Overarching results}
\label{sec:overarching_results}

% summarize discussion of single results
% discuss overall results

\section{Future Work}
\label{sec:future_work}

% dataset increase + assumptions check (maybe other datasets like PLOS)

% bm25 better param search

% idf... imrad based bzw.. not wenn umgedreht

% performance improve (db, serach with document..)

% other dechnoligies of structured text retrieval (not mean over all imrad types)
