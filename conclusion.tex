\chapter{Conclusion}
\label{cha:conclusion}

%In the final chapter we 

\section{Summary}
\label{sec:summary}

We started our work with an motivation section, where we discuss the fast grow of the internet and the resulting importance of search engines. Therefore, search engines help to reduce the time required to find a piece of information, and minimize the number of information sources that need to be searched. In the field of science they help to simplify literature search. 

An advantage of scientific articles is that they have a common structure to increase the readability. This structure is known is IMRaD (Introduction, Method, Results and Discussion). In our work we tackle the question whether it is possible to improve the search result quality while searching for scientific works by using IMRaD structure information. Specifically, 
\begin{enumerate}[label=(\alph*)]
  \item Does the search result improve for explicit search using queries?
  \item Does the search result improve for implicit search using complete scientific papers?
  \item Does the search result improve if only a single chapter of the scientific paper is used for searching?
\end{enumerate}
In the related work section we describe the definition of an information retrieval model. Afterwards, we discuss the $3$ classical models for unstructured text retrieval. First, in the boolean model, documents and queries are represented as sets. Terms are stitched together with boolean operators to formulate user queries. Second, in the vector model, documents and queries are represented asa vector in a t-dimensional space. Third, in the probabilistic model, documents and queries are represented based on probability theory. Specifically by estimating the probability of a term appearing in a relevant document.

Additionally, we describe extensions of the vector-, and the probabilistic model. First, the TF-IDF model is based on the vector space model, and one of the most popular weighting schemes in information retrieval. Second, the BM$25$ model is based on the probabilistic model. It is the result of several experiments by Robertson et. al ~\cite{RobertsonWHGL92, RobertsonWJHG93, RobertsonWJHG94}. Third, the Divergence from Randomness model was introduced by Amati and Rijsbergen ~\cite{AmatiR02} and is a probabilistic model that exhibits characteristics of a language model as well.

Next, we discuss techniques of structured text retrieval models. There we focus specially on $5$ ranking strategies known as contextualization, propagation, aggregation, merging, and zone scores. The model based on zone scores is proposed by Manning et al. ~\cite{manning2008}, and also known as Ranked Boolean Retrieval.

In the last part of the related work we focus on the IMRaD structure in scientific articles. Sollaci and Pereira ~\cite{Sollaci-The-2004} describe in their work that the IMRaD structure began to be adopted in the 1940s, and became the standard format for scientific articles in the 1970s. Furthermore, we discuss IMRaD structure distributions as proposed by Bertin et al. ~\cite{bertin2013}, and how IMRaD structure can be leveraged in information retrieval systems.

In the methods section we started with the description of our generated dataset. There we have $821$ scientific articles in our dataset, and we added additional information like IMRaD mappings, and links between the articles based on citations. Furthermore, we defined our database schema with respect to the article structure and analyze the citation network.

Afterwards, we describe our introduced system and the underlying model. There we design our system to compare various common ranking algorithms. Hence, the ranking algorithms requires to be changeable easily. In addition, our model was designed to work with unstructured as well as structured data. This is reflected by the query language.

In the results and discussion section we describe a measurement for the performance of ranking algorithms. This measurement is required to compare our proposed ranking algorithms.

Next, we list our study results, and discuss a first interpretation. 

% research questions iterrieren


% new chapter
% summarize discussion of single results
% discuss overall results

\section{Future Work}
\label{sec:future_work}

% dataset increase + assumptions check (maybe other datasets like PLOS)

% bm25 better param search

% idf... imrad based bzw.. not wenn umgedreht

% performance improve (db, serach with document..)

% other dechnoligies of structured text retrieval (not mean over all imrad types)
