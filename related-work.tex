\chapter{Related Work}
\label{cha:related_work}

\section{Information Retrieval Models}
\label{sec:information_retrieval_models}

Creating an information retrieval system is a complex process that has to be planned accordingly. To reach this goal models are used as a base, where the whole system is sketched. The model generation consists of two tasks. First, design a framework which represents the documents and the user queries. Second, create a ranking function, which generates a numeric rank for each document based on a query. Afterwards these ranks are used by the system to sort the documents.

One of the most common retrieval approaches is retrieval based on index terms. In this context an index term is a keyword, which appears in the document collection of the framework. This approach can be implemented efficiently as query words can be used as index terms with limited transformations. For example a user is interested in cooking, and searches for "Austrian dishes". The query words "Austrian", and "dishes" can directly used to search through the document collection since they do not need any transformation.

In general, information retrieval models consists of four parts. Ribeiro-Neto and Baeza-Yates ~\cite{ModernInvormationRetrieval1999} define them as a quadruple $[\textbf{D}, \textbf{Q}, \mathcal{F}, \mathcal{R}(q_i, d_j)]$, where:

\begin{enumerate}
  \item \textbf{D} is a set composed of logical views of documents in a collection.
  \item \textbf{Q} is a set composed of logical views of the user information needs. Such representations are called queries.
  \item $\mathcal{F}$ is a framework for modeling document representations, queries, and their relationships.
  \item $\mathcal{R}(q_i, d_j)$ is a raking function that associates a real number with a query representation $q_i \in \textbf{Q}$ and a document representation $d_j \in \textbf{D}$. The ranking function generates an order over all documents \textbf{D} with respect to a query $q_i$.
\end{enumerate}

Hence, the model is used to define the framework $\mathcal{F}$ and the ranking function $\mathcal{R}(q_i, d_j)$. For example, for textual documents the document representation is a set of all terms within the document. To keep the collection smaller without losing any information stop words should be removed in a preprocessing step. The set of index terms within a document collection is called vocabulary. According to our document representation the query representation is a set of all terms within the query. There can also be an additional preprocessing step in the query creation. An example for such an preprocessing step would be synonyms which are added to the query set.

After the design of the framework, a ranking function is created. It should be constructed in a way that it fits to the requirements of the user. This means for a given query, the ranking function determines a numeric rank to each document in the collection, which represents the relevance for the user. For example, the ranking function counts how many query terms appear in the term set of a document.

Another example is to use term frequency as ranking function. Term frequency itself denotes how often a term occurs in a document. To be able to use it, the document representation is adapted from a set with all terms to a bag of words. In a bag of words each term is represented as a pair of term and term frequency. The ranking function sums the frequencies over all query terms. To be able to compare the documents using the term frequency, the ranks are normalized.

Information retrieval is used in several fields where the underlying models have to fulfill different requirements. Therefore, they are separated into text-based models, link-based models, and multimedia objects-based models. Furthermore, text-based models can be categorized in unstructured, and semi-structured text models. Unstructured text models are used for text documents where the content is represented as sequence of words. Semi-structured text models contain structure such as title, sections, paragraphs, in addition to unstructured text.

The web is rapidly growing, and as a consequence has a huge number of web pages (i.e. documents). Therefore, additional information has to be leveraged as well. This means that the content of documents, and furthermore the links between those documents are take into account. Models which use those additional link information are called Link-based models where PageRank ~\cite{brin1998anatomy} and Hyperlink-Induced Topic Search ~\cite{kleinberg1999authoritative} are important parts of the models.

Information retrieval for multimedia objects differs according their underlying data from the first $2$ types. For example, when thinking on a image it can be seen as a matrix of color values. Detecting similarities between images requires the calculation of more complex features, such as shapes. The representation of the query has to be adapted as well. The user can use words, or use images to define a query. One of the simplest forms of multimedia-based retrieval is image retrieval. Audio and video retrieval are more complicated since there is also a time value which have to be taken into account.

\section{Unstructured Text Retrieval}
\label{sec:unstructured_text_Retrieval}

In unstructured text retrieval, documents can be seen as sequence of words. The $3$ classical models are boolean-, vector-, and probabilistic model. First, in the boolean model, documents and queries are represented as sets. Terms are stitched together with boolean operators to formulize user queries. Second, in the vector model, documents and queries are represented as a vector in a t-dimensional space. The size of t is defined by the number of words in the vocabulary of the collection. Third, in the probabilistic model, documents and queries are represented based on probability theory. Specifically by estimating the probability of a term appearing in a relevant document. Gudivada et al. ~\cite{gudivada1997} advice in their work to denote boolean models as set theoretic, vector models as algebraic, and probabilistic models as probabilistic.

\subsection{The Boolean Model}
\label{sec:the_boolean_model}

The boolean model is a well-known information retrieval model in the area of unstructured text retrieval. It was proposed as a paradigm for accessing large-scale systems since the $1950$s ~\cite{Melucci2009}. The model uses boolean operators and set theory to find relevant documents.

\myfig{boolean_model}
      {width=0.65\textwidth}
      {\textbf{Example query in the boolean model with $3$ terms.} For the boolean model documents in the collection are represented as sets of terms. In this example the vocabulary of the document collection is given by V = \{$t_1$, $t_2$, $t_3$\}. Furthermore, documents can be separated according to the terms they are containing. Given a query $q=t_1 \wedge (t_2 \vee \neg t_3)$ all documents which satisfy this query are marked with an green hook. This means that they are relevant for the user. All other documents which does not satisfy the query are marked with a red cross.}
      {Example query in the boolean model with $3$ terms.}
      {fig:boolean_model}

The classic boolean model can only decide if a document is relevant for the user, or not. It does not provide a rank, which is used to sort the documents. Salton et al. introduce in their work ~\cite{Salton-Extended-1983} an extension where documents are sorted according their relevance.

Index terms are combined with the $3$ boolean operators NOT($\neg$), AND($\wedge$), OR($\vee$) to formulize user queries. The disjunctive normal form of the query shows which areas of the sets are relevant. For example, for query $q=t_1 \wedge (t_2 \vee \neg t_3)$, and vocabulary V = \{$t_1$, $t_2$, $t_3$\}, $q_{DNF}$ is:
\begin{equation}
q_{DNF} = (t_1 \wedge t_2 \wedge t_3) \vee (t_1 \wedge t_2 \wedge \neg t_3) \vee (t_1 \wedge \neg t_2 \wedge \neg t_3)
\end{equation}
This representation of the query highlight that $3$ areas are relevant for the user. First, all $3$ query terms occur. Second, the first and the second term occur, but not the third. Finally, the first term occurs, but not the second and the third. \Cref{fig:boolean_model} displays the example query represented in a Venn diagram, where the $3$ areas can be seen in a graphical representation.

The boolean model works also if not all terms of the vocabulary are part of the user query. Considering a vocabulary V = \{$t_1$, $t_2$, $t_3$, $t_4$\}, and the previous example query, the disjunctive normal form is:
\begin{equation}
  \begin{aligned}
    q_{DNF} = &(t_1 \wedge t_2 \wedge t_3 \wedge \neg t_4) \vee (t_1 \wedge t_2 \wedge t_3 \wedge t_4) \vee \\
              &(t_1 \wedge t_2 \wedge \neg t_3 \wedge \neg t_4) \vee (t_1 \wedge t_2 \wedge \neg t_3 \wedge t_4) \vee \\
              &(t_1 \wedge \neg t_2 \wedge \neg t_3 \wedge \neg t_4) \vee (t_1 \wedge \neg t_2 \wedge \neg t_3 \wedge t_4)
  \end{aligned}
\end{equation}
The last term (i.e., $t_4$), which is not part of the query, is also considered in the disjunctive normal form. It is added once as present, and once as absent to the other $3$ terms.

The main advantages of the boolean model are the clean formalism, and its simplicity ~\cite{ModernInvormationRetrieval1999}. These advantages comes with the usage of binary operators, and binary index term weighing. One of the main disadvantages is the exact matching of documents. This means that a document can only be relevant, or not relevant to the user, without any ranking. As a result, users receive too few or too many documents.

\subsection{The Vector Space Model}
\label{sec:the_vector_space_model}

The vector space model was introduced by Salton et al.~\cite{salton75vsm}. In the model documents and queries are represented as vectors in an t-dimensional space, whereas t is the number of words in the vocabulary.

The vector space model is more advanced than the Boolean model, as it contains partial matching. Partial matching means, that a degree of similarity between user queries and documents in the system are calculated. To accomplish this, non-binary weights are used in combination with index terms.

The idea of non-binary weights is based on the assumption that some index terms are more important than others to describe the content of a document. The calculation of such term weights is a challenging task, as they have to reflect the subjective expectation of a user. As a result, terms that appear in a few documents have a higher weight than terms that occur in many documents. 

For example, a collection consists of $3$ documents, given by $D_1 =$ \{"cooking", "appetizer"\}, $D_2 =$ \{"cooking", "main", "dish"\}, and $D_3 =$ \{"cooking", "dessert"\}. A user is interested to prepare a dessert. Therefore he searches for "cooking dessert". The first query word "cooking" is part of each document. This means it is not very useful to define the users requirements. The second query word "dessert" is only part of one document. Therefore, it has more expressiveness than the first term. As a result, the weight of the first term will be smaller than the weight of the second term.

The combination of index terms and weights allows to calculate a numeric rank for each document. These ranks are used to sort the documents ranked by a user query. The resulting list contains the best results on top according to their relevance.

When having a closer look on index terms and their correlations it can be assumed that they are mutually independent. This means knowing $w_{i, j}$, where $w_{i, j}$ is the weight of an index term $t_i$ in a document $d_j$, tells nothing about the next weight $w_{i + 1, j}$. The assumption does not hold, as terms in a document are always related to each other. For example, the words \textit{mobile} and \textit{phone}, which often occur together. Therefore, when a document contains the word \textit{mobile} it is probable that the document also contains the word \textit{phone}. This correlation is reflected in their term weights. The term-term correlation matrix described by Ribeiro-Neto and Baeza-Yates ~\cite{ModernInvormationRetrieval1999} model such relations. It is defined as:
\begin{align}
  \textbf{C} = \textbf{M} \cdot \textbf{M}^T,
\end{align}
where \textbf{M} is a term-document matrix with t rows, and N columns. Each row contains a term of the vocabulary. As a result, the number of rows is equal to the size of the vocabulary. The columns represent the documents collection, where each column contains a single document. Each entry in the matrix \textbf{M} is given a weight $w_{i, j}$ associated with index term $t_i$ and document $d_j$. In the term-term correlation matrix \textbf{C} each element $c_{u, v} \in \textbf{C}$ describes the correlation between the terms $t_u$ and $t_v$, which is given by:
\begin{align}
  c_{u, v} = \sum_{d_j}w_{u, j} \times w_{v, j}.
\end{align}
Therefore the relation between any two terms $t_u$ and $t_v$ is in the matrix. It is based on the joint co-occurrence of the two terms within all documents of the collection. For example, when having a collection of $2$ documents, and the vocabulary of the collection is given by V = \{$t_1$, $t_2$, $t_3$\}. The term-term correlation matrix is calculated as follows:
\begin{samepage}
\[
  \begin{blockarray}{ccc}
    & d_1 & d_2 \\
    \begin{block}{l[cc]}
      t_1 & w_{1, 1} & w_{1, 2} \\
      t_2 & w_{2, 1} & w_{2, 2} \\
      t_3 & w_{3, 1} & w_{3, 2} \\
    \end{block}
  \end{blockarray}
  \hspace{40mm}
  \begin{blockarray}{cccc}
    & t_1 & t_2 & t_3 \\
    \begin{block}{l[ccc]}
      d_1 & w_{1, 1} & w_{2, 1} & w_{3, 1} \\
      d_2 & w_{1, 2} & w_{2, 2} & w_{3, 2} \\
    \end{block}
  \end{blockarray}
    \vspace*{-7mm}
\]
\[
  \hspace{8mm}
  \underbrace{\hspace{2mm}\textbf{M}\hspace{35mm}\times\hspace{35mm}\textbf{M}^{T}}_{\Downarrow} \\
\]
\[
  \begin{blockarray}{cccc}
    & t_1 & t_2 & t_3 \\
    \begin{block}{l[ccc]}
      t_1 & w_{1, 1}w_{1, 1} + w_{1, 2}w_{1, 2} & w_{1, 1}w_{2, 1} + w_{1, 2}w_{2, 2} & w_{1, 1}w_{3, 1} + w_{1, 2}w_{3, 2} \\
      t_2 & w_{2, 1}w_{1, 1} + w_{2, 2}w_{1, 2} & w_{2, 1}w_{2, 1} + w_{2, 2}w_{2, 2} & w_{2, 1}w_{3, 1} + w_{2, 2}w_{3, 2} \\
      t_3 & w_{3, 1}w_{1, 1} + w_{3, 2}w_{1, 2} & w_{3, 1}w_{2, 1} + w_{3, 2}w_{2, 2} & w_{3, 1}w_{3, 1} + w_{3, 2}w_{3, 2} \\
    \end{block}
  \end{blockarray}
\]
\end{samepage}
It can be seen that the term-document matrix \textbf{M} has size $3$ x $2$, where rows consists of the terms, and columns consists of the documents. For example, the weight in the first row, and in the first column $w_{1, 1}$ contains the weight of $t_1$ in document $d_1$. The transposed matrix consists of the terms in the columns, and the documents in the rows. By multiplying these $2$ matrices the term-term correlation matrix \textbf{C} is generated. It has size $3$ x $3$, where rows and columns consists of the terms in the vocabulary. For example, the entry in the first row, and in the second column contains the joint co-occurrence of the terms $t_1$ and $t_2$.

The vector space model is just one information retrieval model which takes advantage of term-term correlation. Other models are the set-based model, fuzzy information retrieval models, and language models.

In the vector space model documents, and queries are represented as vectors in an $t$-dimensional space. The size of $t$ is defined by the size of the vocabulary. As a result, each index term represent one dimension in the vector. Ribeiro-Neto and Baeza-Yates ~\cite{ModernInvormationRetrieval1999} define the document representation $d_j$, and the query representation $q$ as:
\begin{align}
  \vec{d_j} & = (w_{1, j}, w_{2, j}, \dots, w_{t, j}) \\
  \vec{q} & = (w_{1, q}, w_{2, q}, \dots, w_{t, q}).
\end{align}
In both representations the vector consists of term weights which describes their content. Each document in the collection is represented by a document vector $\vec{d_j}$. Thereby $w_{i,j}$ is defined as the weight of term $t_i$ in document $d_j$. It has to be non-negative, and non-binary. The term weights of the query $w_{i, q}$ consists the weight of term $t_i$, which occurs in query $q$. It has to be non-negative.

\myfig{diff_vectors}
      {width=0.5\textwidth}
      {\textbf{Example of the similarity between query and documents in the vector space model.} In this example, the vocabulary of the document collection is given by \mbox{V = \{"\textit{appetizer}", "\textit{dessert}"\}}. The $2$ documents $d_1$, $d_2$, and the query $q$ are represented as vectors according their term weights. The similarity of $2$ vectors is given by the cosine of the angle between them.}
      {Example of the similarity between query and documents in the vector space model.}
      {fig:diff_vectors}

The degree of similarity between a document $d_j$, and a query $q$ is calculated by the cosine of the angle between their corresponding vectors (see \Cref{fig:diff_vectors}). Specifically,
\begin{equation}
  \label{vector_space_similarity}
  \begin{split}
    sim(d_j, q) & = \frac{\vec{d_j} \bullet \vec{q}}{|\vec{d_j}| \times |\vec{q}|} \\
    & = \frac{\sum_{i = 1}^t w_{i, j} \times w_{i, q}}{\sqrt{\sum_{i = 1}^t w_{i, j}^2} \times \sqrt{\sum_{i = 1}^t w_{i, q}^2}},
  \end{split}
\end{equation}
where $\vec{d_j} \bullet \vec{q}$ is the internal product of the $2$ vectors. The factor $|\vec{d_j}|$ is the norm of the document vector, and $|\vec{q}|$ is the norm of query vector. These norms define the document length, and the query length. The norm of the query vector does not affect the ranking result since it is the same for all documents in the collection. Singhal et. al discuss in their work ~\cite{SinghalBM96} more advanced document length normalization for vector space models.

\subsubsection{TF-IDF Weighting Scheme}
\label{sec:tfidf}

Term weighting was first discussed by Luhn ~\cite{Luhn_statistical-1957}. The Author observed that terms that occurs more often in a document are important to describe the content of the document. Therefore, these terms can be seen as keywords. As a result, he assumed that the term frequency $f_{i, j}$, where term $t_i$ occurs in document $d_j$, is relative to the term frequency weight $TF_{i, j}$. Hence, a high term frequency leads to a high term frequency weight. This assumption leads to the following formulation of term frequency weights
\begin{align}
  \label{raw_tf}
  \mathit{tf}_{i, j} = f_{i, j}.
\end{align}
In this formula the raw term frequency is used as term weight. However, Salton and Yang observed in their work ~\cite{FT023} that in some cases term frequency weights are an improvement according binary weights. Furthermore, they state inconsistence in their test results when they changed their test collection, and query set.

To improve the results of term frequency weighting, inverse document frequency weights are used additionally. The concept of inverse document frequency was introduced by SpÃ¤rck Jones ~\cite{jones72astatistical}, and is one of the foundations of term weighting. Therefore, it is used in every modern information retrieval system. The inverse document frequency weight is approximated using Zipf's Law ~\cite{zipf1932selected}
\begin{align}
  \mathit{IDF}_i = \log \frac{N}{n_i}.
\end{align}
It is called inverse document frequency as $n_i/N$ is the relative document frequency. Therefore, is $n_i$ the number of documents, where a term $k_i$ occurs in the document collection, and $N$ is the size of the document collection. The inverse document frequency represents the importance of a term regarding the whole document collection. It is small if a term occurs in almost every document, and it is high if the term appears just in a few documents.

\begin{table}[b!]
    \centering
    \begin{tabular}{ l c }
      \toprule
      \textbf{Weighting scheme} & \textbf{TF Weight} \\ \midrule
      \textit{Binary}  & $\{0, 1\}$  \\
      \textit{Raw Frequency} & $f_{i, j}$  \\
      \textit{Log Normalization} & $1 + \log f_{i, j}$  \\
      \textit{Double Normalization $0.5$} & $0.5 + 0.5 \frac{f_{i, j}}{max f_{i, j}}$  \\
      \textit{Double Normalization K} & $K + (1 - K)\frac{f_{i, j}}{max_i f_{i, j}}$  \\
      \bottomrule
    \end{tabular}
  \caption[Variants of TF weight]{\textbf{Variants of TF weight.} There exist $5$ important variants of term frequency weighting. First, \textit{Binary} weight is the simplest form, and only captures if a term occurs in a document. Second, \textit{Raw Frequency} uses the term frequency directly, and can be seen as base for term frequency weighting. Third, \textit{Log Normalization} is an extension of \textit{Raw Frequency}, and uses the logarithm of the (raw) frequency. Forth, \textit{Double Normalization $0.5$} rescales the weights to be in the range between $0.5$ and $1.0$. Therefore, the weight is always normalized. Fifth, the \textit{Double Normalization K} is a generalization of the \textit{Double Normalization $0.5$}, where K can take values in the range between $0.0$ and $1.0$.}
  \label{tbl:tf_variants}
\end{table}

To use term frequency weighting in combination with inverse document frequency weighting the raw term frequency weight (see \Cref{raw_tf}) has to be adopted to the logarithmic term frequency weight:
\begin{equation}
  \mathit{tf}_{i, j} =
  \begin{cases}
    1 + \log f_{i, j}, & \text{if $f_{i,j} > 0$} \\
    0, & \text{otherwise}.
  \end{cases}
\end{equation}
The log term frequency weight is one of the most frequently used term frequency weighing schemes as the inverse document frequency term weight is also a logarithmic function. Therefore, they can be combined directly as defined by Salton and Yang ~\cite{FT023} to the TF-IDF weighing scheme:
\begin{equation}
  w_{i, j} =
  \begin{cases}
    1 + \log f_{i, j} \times \log \frac{N}{n_i}, & \text{if $f_{i,j} > 0$} \\
    0, & \text{otherwise},
  \end{cases}
\end{equation}
where $w_{i, j}$ is the term weight of term $k_i$, which occurs in document $d_j$. On the one hand, this includes the term frequency, which represents the importance of the term within the document. On the other hand, it is composed of the inverse document frequency, which represents the importance of the term within the whole document collection. The combination of these two weights leads to an effective term weighting scheme. Therefore, it is the base for term weighting that is used in almost every modern information retrieval system.

As the TF-IDF weighting scheme is one of the most popular weighting schemes in information retrieval several variants where proposed over time. Ribeiro-Neto and Baeza-Yates ~\cite{ModernInvormationRetrieval1999} describe in their work the most important forms of term frequency weighting (see \Cref{tbl:tf_variants}), and inverse document weighting (see \Cref{tbl:idf_variants}). Furthermore, they discuss the best combinations of them to compile different TF-IDF weighting schemes for document term weighting, as well as query term weighting. 

\begin{table}[b!]
    \centering
    \begin{tabular}{ l c }
      \toprule
      \textbf{Weighting scheme} & \textbf{IDF Weight} \\ \midrule
      \textit{Unary}  & $1$  \\
      \textit{Inverse Frequency} & $\log \frac{N}{n_i}$  \\
      \textit{Inverse Frequency Smooth} & $\log (1 + \frac{N}{n_i})$  \\
      \textit{Inverse Frequency Max} & $\log (1 + \frac{max_i n_i}{n_i})$  \\
      \textit{Probabilistic Inverse Frequency} & $\log (\frac{N - n_i}{n_i})$  \\
      \bottomrule
    \end{tabular}
  \caption[Variants of inverse document frequency weight]{\textbf{Variants of inverse document frequency weight.} There exist $5$ important variants of inverse document frequency weight. First, the \textit{Unary} form is used to ignore the inverse document frequency. Second, the \textit{Inverse Frequency} is the standard variant as it was initial introduced. Third, the \textit{Inverse Frequency Smooth} adds $1$ to the fracture result. This produces a more representative weight for extreme values of $n_i$. Fourth, the \textit{Inverse Frequency Max} uses the term with the largest document frequency instead of the number of documents in the collection. Therefore the computed weights are relative to the term with the highest document frequency. Fifth, the \textit{Probabilistic Inverse Frequency} subtract the document frequency from the number of documents in the collection. It is the basic form for the probabilistic model, as described in the next section}
  \label{tbl:idf_variants}
\end{table}

For example, given a document $d_1$ = \{"\textit{apple}", "\textit{apple}", "\textit{apple}", "\textit{pear}", "\textit{pear}"\}. When searching for "\textit{pear}", the individual variants of term frequency weighting (see \Cref{tbl:tf_variants}) yield different results. First, \textit{Binary} weight captures if the term occurs in the document. Therefore, the weight of $d_1$ is $1$. Second, \textit{Raw Frequency} denotes how often a term occurs in a document. As a result, the weight is $2$. Third, \textit{Log Normalization} uses $1$ for each query term in the document, and adds the logarithmic \textit{Raw Frequency} of the term. Hence, the weight is approximately $1.7$. Fourth, \textit{Double Normalization $0.5$} leverages the constant factor $0.5$, the \textit{Raw Frequency} of a term, and the maximum frequency over all terms to normalize weights in the range between $0.5$ and $1.0$. The result of the document weight is $0.8\overline{3}$. Fifth, \textit{Double Normalization K} is a generalization of the \textit{Double Normalization $0.5$}. For example, if K is $0.1$, the weighting value lies between $0.1$ and $1$.

To illustrate inverse term frequency, in addition to to $d_1$, the document collection also contains $d_2$ = \{"\textit{apple}", "\textit{peach}"\}. When searching for "\textit{apple}" all documents of the collection contain the term. Therefore, the term is not useful to differentiate documents of the collection. As a result, the inverse document frequency weight is the minimum possible outcome for each weighting scheme (see \Cref{tbl:idf_variants}). When searching for "\textit{pear}" $1$ of $2$ documents contain the term. Hence, the individual variants of inverse document frequency weighting lead to different results. First, the \textit{Unary} variant is always $1$. Second, the \textit{Inverse Frequency} variant denotes $N$ as the number of all documents in the collection. Additionally, $n_i$ is the document frequency of the query term. The logarithm of these to values leads approximately to $0.7$. Third, \textit{Inverse Frequency Smooth} also uses $N$ and $n_i$. In contrast to \textit{Inverse Frequency}, 1 is added inside the logarithm, which results of a weight of approximately $1.1$. Fourth, the \textit{Inverse Frequency Max} is similar to the \textit{Inverse Frequency Smooth}, however uses the term with the largest document frequency instead of $N$. In our example that is "\textit{apple}", which occurs in every document. Therefore, the result is also approximately $1.1$. Fifth, the \textit{Probabilistic Inverse Frequency} is similar to the \textit{Inverse Frequency}, however subtracted $N$ by $n_i$ inside the logarithm. This leads to an inverse term frequency weight of $0.0$.

\begin{table}[b]
    \centering
    \begin{tabular}{ c c }
      \toprule
      \textbf{Document term weight} & \textbf{Query term weight} \\ \midrule
      $f_{i, j}$  & $(0.5 + 0.5 \frac{f_{i, q}}{max_i f_{i, q}}) \times \log \frac{N}{n_i}$  \\
      $1 + \log f_{i, j}$ & $\log (1 + \frac{N}{n_i})$  \\
      $(1 + \log f_{i, j} \times \log \frac{N}{n_i})$ & $(1 + \log f_{i, q}) \times \log \frac{N}{n_i}$  \\
      \bottomrule
    \end{tabular}
  \caption[Recommended variants of the TF-IDF weighting scheme]{\textbf{Recommended variants of the TF-IDF weighting scheme.} There exist $3$ recommended variants of the TF-IDF weighting scheme. Given different document collections the best performing form could vary. They combine term frequency weighing variants with inverse frequency weighing variants. Additionally, they distinguish between document term weights, and query term weights.}
  \label{tbl:recommended_tfidf_weights}
\end{table}
There exist several forms of TF-IDF weighting schemes. The best performing variant could vary given different document collections. In \Cref{tbl:recommended_tfidf_weights} are $3$ recommended combinations, which were proposed by Salton ~\cite{salton1971}. The author distinguishes between document term weights, and query term weights. 
\begin{enumerate} 
	\item The first variant combines the \textit{Raw Frequency} of the term frequency weighing variants in \Cref{tbl:tf_variants}, and the \textit{Inverse Frequency} of the inverse frequency weighing variants in \Cref{tbl:idf_variants} for the document term weight. The associated query term weight uses \textit{Double Normalization $0.5$} and also \textit{Inverse Frequency}.
	\item The second variant differs, as document terms consist only of a term frequency weight, and query terms consists only of a inverse frequency weight. It uses the \textit{Log Normalization} as term frequency weight, and the \textit{Inverse Frequency Smooth} as inverse frequency weight.
  \item The third variant is the initial variant, as it was defined by Salton and Yang ~\cite{FT023}. It combines the \textit{Log Normalization}, and the \textit{Inverse Frequency} for document-, and query terms.
\end{enumerate}

The third variant is the most common used form in the vector space model. Ribeiro-Neto and Baeza-Yates ~\cite{ModernInvormationRetrieval1999} describe in their work an extension for this variant to retrieve better results. There the document term weight, and the query term weight should only be used if the term frequency is greater than $0$, otherwise the corresponding weight is $0$. In the web it is common that the query term frequency is $1$. Therefore, it should be reduced to the inverse document frequency. If this is done, the similarity (see \Cref{vector_space_similarity}) captures $TF \times IDF^2$. To bring it back to the $TF \times IDF$ form, the document term weight is reduced to the term frequency weight $TF$. The second variant is based on the same basic principle.

The TF-IDF weighting scheme can also be used as a ranking function with limited knowledge about vectors. Manning et. al ~\cite{manning2008} describe in their work such a TF-IDF ranking function:
\begin{align}
  \begin{split}
    \text{Score}(q, d) & = \sum_{i \in q} \text{tf-idf}_{i, d} \\
    \text{tf-idf}_{i, d} & = f_{i, q} \times \log \frac{N}{n_i},
  \end{split}
\end{align}
where the query q, and a document d are passed into the ranking function. The query and the document can be seen as sets of terms. To calculate the rank, the TF-IDF weights are summed up. For every query term that does not occur in the document the weight is $0$. For the calculation the \textit{Raw Frequency} term frequency weighing, and the \textit{Inverse Frequency} inverse frequency weighing is used (see \Cref{tbl:tf_variants}, and \Cref{tbl:idf_variants}). 

The TF-IDF weighting scheme is one of the most popular weighting schemes in information retrieval as it is leveraged, adapted and optimized for a wide array of different use-cases.

\subsection{The Probabilistic Model}
\label{sec:the_probabilistic_model}

The first probabilistic model was introduced by Robertson and Sparck Jones ~\cite{Robertson1976}. In their work they defined the probabilistic relevance model as framework for future models. Given an user query the challenge is to find the set of documents which contains exactly the relevant documents. This set of documents is called the ideal answer set.
% continue page 80...

\subsubsection{Okapi BM25}
\label{sec:okapi_bm25}
as described in ~\cite{manning2008} page 214 and in ~\cite{ModernInvormationRetrieval1999} page 105
\begin{equation}
  \begin{split}
    \text{idf}_t & = log \frac{N - \text{df}_t + 0.5}{\text{df}_t + 0.5} \\
    \text{bm25}_{t, d} & = \text{idf}_t \cdot \frac{\text{tf}_{t, d} \cdot (k_1 + 1)}{\text{tf}_{t, d} + k_1 \cdot \bigl(1 - b \cdot \frac{|G|}{\text{avgdl}}\bigr)}  \\
    \text{Score}(q, d) & = \sum_{t \in q}\text{bm25}_{t, d}
  \end{split}
\end{equation}


\subsubsection{Divergence from Randomness}
\label{sec:divergence_from_randomness}

as described in ~\cite{ModernInvormationRetrieval1999} page 113
\begin{equation}
  w_{i, j} = (- \log P(k_i | C)) \cdot (1 - P(k_i | d_j))
\end{equation}
\begin{equation}
  \text{Score}(d_j, q) = \sum_{k_i \in q} f_{i, q} \cdot w_{i, j}
\end{equation}
\begin{equation}
  F_i = \sum_j f_{i, j}
\end{equation}
\begin{equation}
  P(k_i | C) = \binom{F_i}{f_{i, j}}p^{f_{i, j}} \cdot (1 - p)^{F_i - f_{i, j}}
\end{equation}
\begin{equation}
  \lambda_i = p \cdot F_i
\end{equation}
\begin{equation}
  P(k_i | C) = \frac{e^{-\lambda_i}\lambda_i^{f_{i, j}}}{f_{i, j}!}
\end{equation}
\begin{equation}
  \begin{split}
    - \log P(k_i | C) & = -\log\Biggl(\frac{e^{-\lambda_i}\lambda_i^{f_{i, j}}}{f_{i, j}!}\Biggr) \\
    & \approx -f_{i,j} \log \lambda_i + \lambda_i \log e + log(f_{i,j}!) \\
    & \approx f_{i, j} \log \Bigl( \frac{f_{i, j}}{\lambda_i} \Bigr) + \Bigl( \lambda_i + \frac{1}{12 f_{i, j} + 1} - f_{i, j}\Bigr) \log e + \frac{1}{2} \log(2 \pi f_{i, j})
  \end{split}
\end{equation}
\begin{equation}
  1 - P(k_i | d_j) = \frac{1}{f_{i, j} + 1}
\end{equation}
\begin{equation}
  f^{\prime}_{i, j} = f_{i, j} \cdot \frac{avgdl}{len(d_j)}
\end{equation}

\section{Structured Text Retrieval}
\label{sec:structured_text_Retrieval}

Write about structuring, early text retrieval, xml retrieval

\subsubsection{Ranked Boolean Retrieval}
\label{sec:ranked_boolean_retrieval}

Described in ~\cite{manning2008} page 103

\begin{equation}
  \sum_{i = 1}^{l}g_i s_i
\end{equation}

\section{Document Preprocessing}
\label{sec:document_preprocessing}

~\cite{ModernInvormationRetrieval1999} page 223
Describe Text Similarities and common techniques. ~\cite{ModernInvormationRetrieval1999} page 222

\subsection{Stop Words}
\label{subsec:stop_words}

What are stopwords, and describe common techniques. In ~\cite{Vijayarani2015} and references

\subsection{Stemming}
\label{subsec:stemming}

Describe stemming and common stemming techniques. In ~\cite{Vijayarani2015} and references

\section{Text Similarities}
\label{sec:text_similarities}

Describe Text Similarities and common techniques. ~\cite{ModernInvormationRetrieval1999} page 222

\section{IMRaD Structure}
\label{sec:imrad_structure}

general about IMRaD in scientific writing: ~\cite{robert1989}, chapter distribution analysis: ~\cite{bertin2013} important: ~\cite{Sollaci-The-2004}

\section{Evaluation of Ranking Algorithms}
\label{sec:evaluation_of_ranking_algorithms}

as described in ~\cite{manning2008} page 147 and in ~\cite{ModernInvormationRetrieval1999} page 140

\myfig{precision_recall}
      {width=0.50\textwidth}
      {Precision and Recall}
      {Precision and Recall}
      {fig:precision_recall}

\begin{equation}
  P = \frac{\text{\# relevant items retrieved}}{\text{\# retrieved items}} = \frac{TP}{TP + FP} = P(\text{relevant} | \text{retrieved})
\end{equation}

\myfig{map}
      {width=1.00\textwidth}
      {Example for the precision of a search result}
      {Example for the precision of a search result}
      {fig:map}

\begin{equation}
  \text{MAP}(Q) = \frac{1}{|Q|}\sum_{j = 1}^{|Q|} \frac{1}{m_j}\sum_{k = 1}^{m_j}\text{Precision}(R_{jk})
\end{equation}
